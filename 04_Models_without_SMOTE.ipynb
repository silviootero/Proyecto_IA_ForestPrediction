{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpafUqZiMNJqFyN4WkLQmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silviootero/Proyecto_IA_ForestPrediction/blob/main/04_Models_without_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_V5lY8H3k2S"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,mean_absolute_error, accuracy_score, mean_squared_error, precision_score, f1_score,recall_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import recall_score\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "metadata": {
        "id": "A1j1RGC131GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastparquet"
      ],
      "metadata": {
        "id": "cTS8bLXO30-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('https://mlearner.s3.amazonaws.com/data/clean_data.parquet')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "l77qTIkj3021"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.lstrip()"
      ],
      "metadata": {
        "id": "BGyUmln730sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower() for name in df.columns]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "01oapgvV3_wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "9vPgasol3_mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "6U6eVhxv4DIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['id'].value_counts())\n",
        "sns.countplot(x=df['id'])"
      ],
      "metadata": {
        "id": "ua1lEn_L4RFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('id', axis=1).values\n",
        "Y = df['id'].values\n",
        "print (X.shape , Y.shape)\n",
        "#1"
      ],
      "metadata": {
        "id": "lhwJJpii4Q7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "gBHbjTZm4Uxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "ri7Dv5fC4UnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,stratify=Y,test_size=0.30)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "uVH5tHXD4uqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #NORMALIZAR\n",
        "def calcularMatrizCF(matrix,titulo):\n",
        "    a = (matrix[0,0] +  matrix[0,1])\n",
        "    b = (matrix[1,0] +  matrix[1,1])\n",
        "    matrix[0,0] =  matrix[0,0] / a\n",
        "    matrix[0,1] =  matrix[0,1] / a\n",
        "    matrix[1,0] =  matrix[1,0] / b\n",
        "    matrix[1,1] =  matrix[1,1] / b\n",
        "    #MATRIZ DE CONFUSION\n",
        "    sns.heatmap(matrix,annot=True)\n",
        "    plt.xlabel('Label Pred')\n",
        "    plt.ylabel('Label True')\n",
        "    plt.title(titulo)\n",
        "    print(matrix)"
      ],
      "metadata": {
        "id": "FonTJTvo4ug4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_boosting_tree(X,y,num_trees):\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=4)\n",
        "    \n",
        "    resultados = pd.DataFrame()\n",
        "    conf_matrix_list_of_arrays = np.zeros(2)\n",
        "    \n",
        "    idx = 0\n",
        "    \n",
        "    for trees in num_trees:\n",
        "        EficienciaTrain = []\n",
        "        EficienciaVal = []\n",
        "        accuracy = []\n",
        "        Macc = []\n",
        "        Mpre = []\n",
        "        Mrec = []\n",
        "        Mf1 = []\n",
        "        print(f\"Training with {trees} trees...\")\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            model = GradientBoostingClassifier(n_estimators=trees)\n",
        "            model.fit(X_train,y_train)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_pred_train = model.predict(X_train)\n",
        "\n",
        "            conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "            conf_matrix_list_of_arrays = conf_matrix_list_of_arrays + conf_matrix\n",
        "\n",
        "            EficienciaTrain.append(np.mean(y_pred_train.ravel() == y_train.ravel()))\n",
        "            EficienciaVal.append(np.mean(y_pred.ravel() == y_test.ravel()))\n",
        "            accuracy.append(model.score(X_test, y_test))\n",
        "            Macc.append(accuracy_score(y_test, y_pred))\n",
        "            Mpre.append(precision_score(y_test, y_pred))\n",
        "            Mrec.append(recall_score(y_test, y_pred))\n",
        "            Mf1.append(f1_score(y_test, y_pred,average=\"weighted\"))\n",
        "\n",
        "        resultados.loc[idx,'número de arboles'] = trees\n",
        "        resultados.loc[idx,'eficiencia de entrenamiento'] = np.mean(EficienciaTrain)\n",
        "        resultados.loc[idx,'desviacion estandar entrenamiento'] = np.std(EficienciaTrain)\n",
        "        resultados.loc[idx,'eficiencia de prueba'] = np.mean(EficienciaVal)\n",
        "        resultados.loc[idx,'Intervalo de confianza (prueba)'] = np.std(EficienciaVal)\n",
        "        resultados.loc[idx,'accuracy real'] = np.mean(Macc)\n",
        "        resultados.loc[idx,'precision_score'] = np.mean(Mpre)\n",
        "        resultados.loc[idx,'recall_score'] = np.mean(Mrec)\n",
        "        resultados.loc[idx,'f1_score'] = np.mean(Mf1)\n",
        "        idx= idx +1\n",
        "\n",
        "    return (resultados, conf_matrix_list_of_arrays)"
      ],
      "metadata": {
        "id": "TxAi29zq4zuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_gbt, matrix_gbt = gradient_boosting_tree(X_train,y_train,[20,50,100,200,300])"
      ],
      "metadata": {
        "id": "kxUKxzml4zhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_gbt"
      ],
      "metadata": {
        "id": "Sf_D2X8147Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcularMatrizCF(matrix_gbt, \"Matriz de confusión GBT\")"
      ],
      "metadata": {
        "id": "P8Ga3J815DLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ejercicio de código\n",
        "def support_vector_machine(x, y, kernels, gammas,params_reg):\n",
        "    \n",
        "    idx = 0\n",
        "    \n",
        "    kf = StratifiedKFold(n_splits=4)\n",
        "    \n",
        "    # crear una lista con la combinaciones de los elementos de cada list\n",
        "    kernels_gammas_regs = list(itertools.product(kernels, gammas, params_reg))\n",
        "    \n",
        "    resultados = pd.DataFrame()\n",
        "    conf_matrix_list_of_arrays = np.zeros(2)\n",
        "    \n",
        "    for params in kernels_gammas_regs:\n",
        "        kernel, gamma, param_reg = params\n",
        "        ''' print(\"parametros usados\", params) # puede usar para ver los params '''\n",
        "        errores_train = []\n",
        "        errores_test = []\n",
        "        EficienciaVal = []\n",
        "        pct_support_vectors = []\n",
        "        Macc = []\n",
        "        Mpre = []\n",
        "        Mrec = []\n",
        "        Mf1 = []\n",
        "        print(f\"Running with Kernel: {kernel}, Gamma: {gamma}, C: {param_reg} parameters...\")\n",
        "        for train_index, test_index in kf.split(x,y):\n",
        "            X_train, X_test = x[train_index], x[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]  \n",
        "   \n",
        "            svm = SVC(kernel=kernel, gamma=gamma, C= param_reg)\n",
        "            # Entrenar el modelo\n",
        "            svm.fit(X=X_train, y=y_train)\n",
        "            # calculo de errores\n",
        "            \n",
        "            y_train_pred = svm.predict(X=X_train)\n",
        "            y_test_pred = svm.predict(X=X_test)\n",
        "            \n",
        "            conf_matrix = confusion_matrix(y_test, svm.predict(X_test))\n",
        "            conf_matrix_list_of_arrays = conf_matrix_list_of_arrays + conf_matrix\n",
        "            \n",
        "            # error y pct de vectores de soporte\n",
        "            errores_train.append(accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
        "            errores_test.append(accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
        "            \n",
        "            # contar muestras de entrenamiento\n",
        "            n_train = X_train.shape[0]\n",
        "            pct_vs = ( svm.support_vectors_.shape[0] /n_train)\n",
        "            pct_support_vectors.append(pct_vs)\n",
        "            \n",
        "            Macc.append(accuracy_score(y_test, y_test_pred))\n",
        "            Mpre.append(precision_score(y_test, y_test_pred))\n",
        "            Mrec.append(recall_score(y_test, y_test_pred))\n",
        "            Mf1.append(f1_score(y_test, y_test_pred,average=\"weighted\",labels=np.unique(y_test_pred)))\n",
        "            EficienciaVal.append(np.mean(y_test_pred.ravel() == y_test.ravel()))\n",
        "\n",
        "    \n",
        "        resultados.loc[idx,'kernel'] = kernel\n",
        "        resultados.loc[idx,'gamma'] = gamma\n",
        "        resultados.loc[idx,'param_reg'] = param_reg\n",
        "        resultados.loc[idx,'error de entrenamiento'] = np.mean(errores_train)\n",
        "        resultados.loc[idx,'error de prueba'] = np.mean(errores_test)\n",
        "        resultados.loc[idx,'% de vectores de soporte'] = np.mean(pct_support_vectors)*100\n",
        "        resultados.loc[idx,'accuracy real'] = np.mean(Macc)\n",
        "        resultados.loc[idx,'Intervalo de confianza (prueba)'] = np.std(EficienciaVal)\n",
        "        resultados.loc[idx,'precision_score'] = np.mean(Mpre)\n",
        "        resultados.loc[idx,'recall_score'] = np.mean(Mrec)\n",
        "        resultados.loc[idx,'f1_score'] = np.mean(Mf1)\n",
        "\n",
        "        idx+=1\n",
        "    return (resultados, conf_matrix_list_of_arrays)"
      ],
      "metadata": {
        "id": "q9NbG2RR5F2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a realizar los experimentos\n",
        "resultados_svm, matrix_svm  = support_vector_machine(x = X,y=Y,\n",
        "                                 kernels=['rbf'],\n",
        "                                 gammas = [0.01],\n",
        "                                 params_reg = [0.01]\n",
        "                                )\n",
        "resultados_svm"
      ],
      "metadata": {
        "id": "YmXjtTHe5LnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_svm"
      ],
      "metadata": {
        "id": "kFDiLUUH5PPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcularMatrizCF(matrix_svm, \"Matriz de confusión SVM\")"
      ],
      "metadata": {
        "id": "l6mmT48q5TDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ejercicio de código\n",
        "def random_forest(num_trees,numero_de_variables, X, Y):\n",
        "    folds = 4\n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    conf_matrix_list_of_arrays = np.zeros(2)\n",
        "    \n",
        "    for trees in num_trees:\n",
        "        \n",
        "        for num_variables in numero_de_variables:\n",
        "            ## para almacenar los errores intermedios\n",
        "            EficienciaTrain = []\n",
        "            EficienciaVal = []\n",
        "            Macc = []\n",
        "            Mpre = []\n",
        "            Mrec = []\n",
        "            Mf1 = []\n",
        "            for train, test in skf.split(X, Y):\n",
        "                Xtrain = X[train,:]\n",
        "                Ytrain = Y[train]\n",
        "                Xtest = X[test,:]\n",
        "                Ytest = Y[test]\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                modelo = RandomForestClassifier(n_estimators=trees, max_features=num_variables, criterion=\"gini\")\n",
        "                modelo.fit(Xtrain,Ytrain)\n",
        "                #predecir muestras de entrenamiento\n",
        "                Ytrain_pred = modelo.predict(Xtrain)\n",
        "                #predecir muestras de pruebas\n",
        "                Yest = modelo.predict(Xtest)\n",
        "                #Evaluamos las predicciones del modelo con los datos de test\n",
        "                EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "                EficienciaVal.append(np.mean(Yest.ravel() == Ytest.ravel()))\n",
        "                conf_matrix = confusion_matrix(Ytest, modelo.predict(Xtest))\n",
        "                conf_matrix_list_of_arrays = conf_matrix_list_of_arrays + conf_matrix\n",
        "                Macc.append(accuracy_score(Ytest, Yest))\n",
        "                Mpre.append(precision_score(Ytest, Yest))\n",
        "                Mrec.append(recall_score(Ytest, Yest))\n",
        "                Mf1.append(f1_score(Ytest, Yest))\n",
        "\n",
        "\n",
        "\n",
        "            resultados.loc[idx,'número de arboles'] = trees\n",
        "            resultados.loc[idx,'variables para la selección del mejor umbral'] = num_variables\n",
        "            resultados.loc[idx,'eficiencia de entrenamiento'] = np.mean(EficienciaTrain)\n",
        "            resultados.loc[idx,'desviacion estandar entrenamiento'] = np.std(EficienciaTrain)\n",
        "            resultados.loc[idx,'eficiencia de prueba'] = np.mean(EficienciaVal)\n",
        "            resultados.loc[idx,'Intervalo de confianza (prueba)'] = np.std(EficienciaVal)\n",
        "            resultados.loc[idx,'accuracy real'] = np.mean(Macc)\n",
        "            resultados.loc[idx,'precision_score'] = np.mean(Mpre)\n",
        "            resultados.loc[idx,'recall_score'] = np.mean(Mrec)\n",
        "            resultados.loc[idx,'f1_score'] = np.mean(Mf1)\n",
        "            idx= idx +1\n",
        "        print(f\"Termina para {trees} arboles\")\n",
        "        \n",
        "    return (resultados, conf_matrix_list_of_arrays)"
      ],
      "metadata": {
        "id": "_2FkKN5A5Vit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles = [5,10,20,50,100, 150]\n",
        "variables_seleccion = [5,10,15,20,25]\n",
        "resultados_rf, matrixRF= random_forest(arboles, variables_seleccion, X, Y)\n",
        "resultados_rf"
      ],
      "metadata": {
        "id": "O_ViFwrb5ZoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcularMatrizCF(matrixRF, \"Matriz de confusión RF\")"
      ],
      "metadata": {
        "id": "Vi21EMjt5dXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}