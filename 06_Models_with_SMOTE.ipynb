{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrYxjFZo6YunKI5qs6xuGN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silviootero/Proyecto_IA_ForestPrediction/blob/main/06_Models_with_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq5DwS3_C6o9"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "!pip install catboost\n",
        "!pip install pyarrow\n",
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "metadata": {
        "id": "EpjHxazQFcZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastparquet"
      ],
      "metadata": {
        "id": "T_vvlZWkFcPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import sklearn\n",
        "import xgboost\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve\n",
        "from imblearn.pipeline import Pipeline\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
      ],
      "metadata": {
        "id": "PB8F_pc4FcLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('https://mlearner.s3.amazonaws.com/data/clean_data.parquet')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5tZGh2rUFcI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.lstrip()"
      ],
      "metadata": {
        "id": "1iYLVldXFcGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower() for name in df.columns]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "70wNIHbWFcD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "UCymUwnLFcBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "8ZNJfWX2Fb-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['id'].value_counts())\n",
        "sns.countplot(x=df['id'])"
      ],
      "metadata": {
        "id": "iEyfpYrNFb7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = df['id']\n",
        "df = df.drop(['id'], axis = 1)"
      ],
      "metadata": {
        "id": "QviN85JNFb37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas"
      ],
      "metadata": {
        "id": "8_gQBSgBFbx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OUj3VlIaF3MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "fil, col = df.shape\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "ALL_PCA = PCA(col, random_state=None,\n",
        "                svd_solver='auto', tol=0.0, whiten=False).fit(df)\n",
        "ALL_Componentes = np.cumsum(ALL_PCA.explained_variance_ratio_)\n",
        "print(ALL_Componentes)"
      ],
      "metadata": {
        "id": "8vd7Bb0tF3EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot(np.arange(len(ALL_Componentes)), ALL_Componentes)\n",
        "pyplot.xlabel('Componentes Principales')\n",
        "pyplot.ylabel('Varianza Acumulada')\n",
        "pyplot.title('PCA con Varianza Acumulada')\n",
        "pyplot.xlim(0, len(ALL_Componentes))\n",
        "pyplot.ylim(0, 1)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "5pkaDjUqF27f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_COMPONENTS = 65"
      ],
      "metadata": {
        "id": "f5T2eyzgF_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_df = PCA(n_components=N_COMPONENTS)\n",
        "pca_df.fit(df)\n",
        "df_pca = pd.DataFrame(pca_df.transform(df))"
      ],
      "metadata": {
        "id": "qB0eLxl6GD5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test  = train_test_split(df_pca, etiquetas, test_size=0.1, stratify = etiquetas, random_state = 42)"
      ],
      "metadata": {
        "id": "AGRs5t0PGGVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "\n",
        "for index_train, index_test in skf.split(X_train, y_train):\n",
        "    X_train_sm, X_val_sm = X_train.iloc[index_train], X_train.iloc[index_test]\n",
        "    y_train_sm, y_val_sm = y_train.iloc[index_train], y_train.iloc[index_test]\n",
        "\n",
        "X_train_sm = X_train_sm.values\n",
        "X_val_sm = X_val_sm.values\n",
        "y_train_sm = y_train_sm.values\n",
        "y_val_sm = y_val_sm.values"
      ],
      "metadata": {
        "id": "WYXV4agCGJOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lst_reg = []\n",
        "precision_lst_reg = []\n",
        "recall_lst_reg = []\n",
        "f1_lst_reg = []\n",
        "auc_lst_reg = []\n",
        "\n",
        "log_reg_sm = LogisticRegression()\n",
        "log_reg_params = {\"penalty\": ['l2'],\n",
        "                  'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "                  'class_weight': ['balanced',None],\n",
        "                  'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "\n",
        "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
        "\n",
        "\n",
        "for train, val in skf.split(X_train_sm, y_train_sm):\n",
        "    pipeline_reg = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
        "    model_reg = pipeline_reg.fit(X_train_sm[train], y_train_sm[train])\n",
        "    best_est_reg = rand_log_reg.best_estimator_\n",
        "    prediction_reg = best_est_reg.predict(X_train_sm[val])\n",
        "    \n",
        "    accuracy_lst_reg.append(pipeline_reg.score(X_train_sm[val], y_train_sm[val]))\n",
        "    precision_lst_reg.append(precision_score(y_train_sm[val], prediction_reg))\n",
        "    recall_lst_reg.append(recall_score(y_train_sm[val], prediction_reg))\n",
        "    f1_lst_reg.append(f1_score(y_train_sm[val], prediction_reg))\n",
        "    auc_lst_reg.append(roc_auc_score(y_train_sm[val], prediction_reg))\n",
        "\n",
        "\n",
        "print('Logistic Regression (SMOTE) results:')\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst_reg)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst_reg)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst_reg)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst_reg)))"
      ],
      "metadata": {
        "id": "AcRvcKAQGJET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_log_reg.best_params_"
      ],
      "metadata": {
        "id": "oiNHEUZOGPhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = ['Fin.Stable', 'Fin.Unstable']\n",
        "pred_reg_sm = best_est_reg.predict(X_val_sm)\n",
        "print(classification_report(y_val_sm, pred_reg_sm, target_names=label))"
      ],
      "metadata": {
        "id": "nSUX1krqGPYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lst_xgb = []\n",
        "precision_lst_xgb = []\n",
        "recall_lst_xgb = []\n",
        "f1_lst_xgb = []\n",
        "auc_lst_xgb = []\n",
        "\n",
        "xgb_sm = xgboost.XGBClassifier(random_state = 42)\n",
        "xgb_params = {'eta' : [0.1,0.01,0.001], \n",
        "              'eval_metric': ['logloss'],\n",
        "              'max_depth' : [3,6,9],\n",
        "              'lambda' : [1,1.5,2],      \n",
        "              'alpha' : [0,0.5,1]}       \n",
        "        \n",
        "rand_xgb = RandomizedSearchCV(xgb_sm, xgb_params, n_iter=4)\n",
        "\n",
        "\n",
        "for train, val in skf.split(X_train_sm, y_train_sm):\n",
        "    pipeline_xgb = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_xgb) # SMOTE happens during Cross Validation not before..\n",
        "    model_xgb = pipeline_xgb.fit(X_train_sm, y_train_sm)\n",
        "    best_est_xgb = rand_xgb.best_estimator_\n",
        "    prediction_xgb = best_est_xgb.predict(X_train_sm[val])\n",
        "    \n",
        "    accuracy_lst_xgb.append(pipeline_xgb.score(X_train_sm[val], y_train_sm[val]))\n",
        "    precision_lst_xgb.append(precision_score(y_train_sm[val], prediction_xgb))\n",
        "    recall_lst_xgb.append(recall_score(y_train_sm[val], prediction_xgb))\n",
        "    f1_lst_xgb.append(f1_score(y_train_sm[val], prediction_xgb))\n",
        "    auc_lst_xgb.append(roc_auc_score(y_train_sm[val], prediction_xgb))\n",
        "    \n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst_xgb)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst_xgb)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst_xgb)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst_xgb)))\n",
        "print('---' * 45)"
      ],
      "metadata": {
        "id": "AHeJctn4GT8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_xgb.best_params_"
      ],
      "metadata": {
        "id": "1-0CPRvSGXUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote_prediction_xgb = best_est_xgb.predict(X_val_sm)\n",
        "print(classification_report(y_val_sm, smote_prediction_xgb, target_names=label))"
      ],
      "metadata": {
        "id": "aPVsXdjJGXNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lst_rfc = []\n",
        "precision_lst_rfc = []\n",
        "recall_lst_rfc = []\n",
        "f1_lst_rfc = []\n",
        "auc_lst_rfc = []\n",
        "\n",
        "rfc_sm = RandomForestClassifier()\n",
        "rfc_params = {'max_features' : ['auto', 'sqrt', 'log2'],\n",
        "              'random_state' : [42],\n",
        "              'class_weight' : ['balanced','balanced_subsample'],\n",
        "              'criterion' : ['gini', 'entropy'],\n",
        "              'bootstrap' : [True, False]}\n",
        "    \n",
        "    \n",
        "rand_rfc = RandomizedSearchCV(rfc_sm, rfc_params, n_iter=4)\n",
        "\n",
        "\n",
        "for train, val in skf.split(X_train_sm, y_train_sm):\n",
        "    pipeline_rfc = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_rfc)\n",
        "    model_rfc = pipeline_rfc.fit(X_train_sm, y_train_sm)\n",
        "    best_est_rfc = rand_rfc.best_estimator_\n",
        "    prediction_rfc = best_est_rfc.predict(X_train_sm[val])\n",
        "    \n",
        "    accuracy_lst_rfc.append(pipeline_rfc.score(X_train_sm[val], y_train_sm[val]))\n",
        "    precision_lst_rfc.append(precision_score(y_train_sm[val], prediction_rfc))\n",
        "    recall_lst_rfc.append(recall_score(y_train_sm[val], prediction_rfc))\n",
        "    f1_lst_rfc.append(f1_score(y_train_sm[val], prediction_rfc))\n",
        "    auc_lst_rfc.append(roc_auc_score(y_train_sm[val], prediction_rfc))\n",
        "    \n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst_rfc)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst_rfc)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst_rfc)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst_rfc)))"
      ],
      "metadata": {
        "id": "7FQCZ06sGbfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_rfc.best_params_"
      ],
      "metadata": {
        "id": "f3Labo8IGbZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = ['Fin.Stable', 'Fin.Unstable']\n",
        "smote_prediction_rfc = best_est_rfc.predict(X_val_sm)\n",
        "print(classification_report(y_val_sm, smote_prediction_rfc, target_names=label))"
      ],
      "metadata": {
        "id": "KKuSDyxOGg9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lst_gbc = []\n",
        "precision_lst_gbc = []\n",
        "recall_lst_gbc = []\n",
        "f1_lst_gbc = []\n",
        "auc_lst_gbc = []\n",
        "\n",
        "gbc_sm = GradientBoostingClassifier()\n",
        "gbc_params = {'max_features' : ['auto', 'sqrt', 'log2'],\n",
        "              'random_state' : [42],\n",
        "              'n_estimators' : [20,50,100,200,300]}\n",
        "    \n",
        "    \n",
        "rand_gbc = RandomizedSearchCV(gbc_sm, gbc_params, n_iter=4)\n",
        "\n",
        "\n",
        "for train, val in skf.split(X_train_sm, y_train_sm):\n",
        "    pipeline_gbc = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_gbc)\n",
        "    model_gbc = pipeline_gbc.fit(X_train_sm, y_train_sm)\n",
        "    best_est_gbc = rand_gbc.best_estimator_\n",
        "    prediction_gbc = best_est_gbc.predict(X_train_sm[val])\n",
        "    \n",
        "    accuracy_lst_gbc.append(pipeline_gbc.score(X_train_sm[val], y_train_sm[val]))\n",
        "    precision_lst_gbc.append(precision_score(y_train_sm[val], prediction_gbc))\n",
        "    recall_lst_gbc.append(recall_score(y_train_sm[val], prediction_gbc))\n",
        "    f1_lst_gbc.append(f1_score(y_train_sm[val], prediction_gbc))\n",
        "    auc_lst_gbc.append(roc_auc_score(y_train_sm[val], prediction_gbc))\n",
        "    \n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst_gbc)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst_gbc)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst_gbc)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst_gbc)))"
      ],
      "metadata": {
        "id": "uP-sNh3AGg1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_gbc.best_params_"
      ],
      "metadata": {
        "id": "atfPUb8lGmfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote_prediction_gbc = best_est_gbc.predict(X_val_sm)\n",
        "print(classification_report(y_val_sm, smote_prediction_gbc, target_names=label))"
      ],
      "metadata": {
        "id": "sLaAV4KTGo5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lst_cbt = []\n",
        "precision_lst_cbt = []\n",
        "recall_lst_cbt = []\n",
        "f1_lst_cbt = []\n",
        "auc_lst_cbt = []\n",
        "\n",
        "cbt_sm = CatBoostClassifier(verbose = 0)\n",
        "\n",
        "cbt_params = {'eval_metric': ['F1'],\n",
        "              'iterations': [100,500,1000],\n",
        "              'learning_rate' : [0.1,0.01,0.001],\n",
        "              'random_seed' : [42],\n",
        "              'auto_class_weights' : ['Balanced','SqrtBalanced']\n",
        "             }\n",
        "    \n",
        "    \n",
        "rand_cbt = RandomizedSearchCV(cbt_sm, cbt_params, n_iter=4)\n",
        "\n",
        "for train, val in skf.split(X_train_sm, y_train_sm):\n",
        "    pipeline_cbt = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_cbt) # SMOTE happens during Cross Validation not before..\n",
        "    model_cbt = pipeline_cbt.fit(X_train_sm, y_train_sm)\n",
        "    best_est_cbt = rand_cbt.best_estimator_\n",
        "    prediction_cbt = best_est_cbt.predict(X_train_sm[val])\n",
        "    \n",
        "    accuracy_lst_cbt.append(pipeline_cbt.score(X_train_sm[val], y_train_sm[val]))\n",
        "    precision_lst_cbt.append(precision_score(y_train_sm[val], prediction_cbt))\n",
        "    recall_lst_cbt.append(recall_score(y_train_sm[val], prediction_cbt))\n",
        "    f1_lst_cbt.append(f1_score(y_train_sm[val], prediction_cbt))\n",
        "    auc_lst_cbt.append(roc_auc_score(y_train_sm[val], prediction_cbt))\n",
        "    \n",
        "\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst_cbt)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst_cbt)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst_cbt)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst_cbt)))"
      ],
      "metadata": {
        "id": "0qu53YJWG0Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_cbt.best_params_"
      ],
      "metadata": {
        "id": "BREh4ImmG0Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote_prediction_cbt = best_est_cbt.predict(X_val_sm)\n",
        "print(classification_report(y_val_sm, smote_prediction_cbt, target_names=label))"
      ],
      "metadata": {
        "id": "4Tz2sh0lG0Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_est_cbt"
      ],
      "metadata": {
        "id": "CUKd2tXNG9Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_cbt.best_params_"
      ],
      "metadata": {
        "id": "TB0BDpqVHALa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "log_false_positive_rate, log_true_positive_rate, _ = roc_curve(y_val_sm, pred_reg_sm)\n",
        "xgb_false_positive_rate, xgb_true_positive_rate, _ = roc_curve(y_val_sm, smote_prediction_xgb)\n",
        "rfc_false_positive_rate, rfc_true_positive_rate, _ = roc_curve(y_val_sm, smote_prediction_rfc)\n",
        "gbc_false_positive_rate, gbc_true_positive_rate, _ = roc_curve(y_val_sm, smote_prediction_gbc)\n",
        "cat_false_positive_rate, cat_true_positive_rate, _ = roc_curve(y_val_sm, smote_prediction_cbt)\n",
        "\n",
        "\n",
        "def graficar_curvas_ROC(log_false_positive_rate, log_true_positive_rate, rfc_false_positive_rate, rfc_true_positive_rate, xgb_false_positive_rate, xgb_true_positive_rate, cat_false_positive_rate, cat_true_positive_rate, gbc_false_positive_rate, gbc_true_positive_rate):\n",
        "    plt.figure(figsize=(20,8))\n",
        "    plt.title('Curvas ROC', fontsize=14)\n",
        "    plt.plot(log_false_positive_rate, log_true_positive_rate, label='Regresión logística AUC: {:.4f}'.format(roc_auc_score(y_val_sm, pred_reg_sm)))\n",
        "    plt.plot(xgb_false_positive_rate, xgb_true_positive_rate, label='XGBoost AUC: {:.4f}'.format(roc_auc_score(y_val_sm, smote_prediction_xgb)))\n",
        "    plt.plot(cat_false_positive_rate, cat_true_positive_rate, label='CatBoost AUC: {:.4f}'.format(roc_auc_score(y_val_sm, smote_prediction_cbt)))\n",
        "    plt.plot(rfc_false_positive_rate, rfc_true_positive_rate, label='Random Forest AUC: {:.4f}'.format(roc_auc_score(y_val_sm, smote_prediction_rfc)))\n",
        "    plt.plot(gbc_false_positive_rate, gbc_true_positive_rate, label='Gradient Boosting AUC: {:.4f}'.format(roc_auc_score(y_val_sm, smote_prediction_gbc)))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([-0.01, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate', fontsize=14)\n",
        "    plt.ylabel('True Positive Rate', fontsize=14)\n",
        "    plt.legend()\n",
        "    \n",
        "graficar_curvas_ROC(log_false_positive_rate, log_true_positive_rate, rfc_false_positive_rate, rfc_true_positive_rate, xgb_false_positive_rate, xgb_true_positive_rate, cat_false_positive_rate, cat_true_positive_rate, gbc_false_positive_rate, gbc_true_positive_rate)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_tQThrtHAB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_reg = confusion_matrix(y_val_sm, pred_reg_sm, normalize='true')\n",
        "confusion_matrix_xgb = confusion_matrix(y_val_sm, smote_prediction_xgb, normalize='true')\n",
        "confusion_matrix_rfc = confusion_matrix(y_val_sm, smote_prediction_rfc, normalize='true')\n",
        "confusion_matrix_gbc = confusion_matrix(y_val_sm, smote_prediction_gbc, normalize='true')\n",
        "confusion_matrix_cbt = confusion_matrix(y_val_sm, smote_prediction_cbt, normalize='true')\n",
        "\n",
        "heat_cm0 = pd.DataFrame(confusion_matrix_reg, columns=np.unique(y_val_sm), index = np.unique(y_val_sm))\n",
        "heat_cm0.index.name = 'Actual'\n",
        "heat_cm0.columns.name = 'Predicted'\n",
        "\n",
        "heat_cm1 = pd.DataFrame(confusion_matrix_xgb, columns=np.unique(y_val_sm), index = np.unique(y_val_sm))\n",
        "heat_cm1.index.name = 'Actual'\n",
        "heat_cm1.columns.name = 'Predicted'\n",
        "\n",
        "heat_cm2 = pd.DataFrame(confusion_matrix_rfc, columns=np.unique(y_val_sm), index = np.unique(y_val_sm))\n",
        "heat_cm2.index.name = 'Actual'\n",
        "heat_cm2.columns.name = 'Predicted'\n",
        "\n",
        "heat_cm3 = pd.DataFrame(confusion_matrix_gbc, columns=np.unique(y_val_sm), index = np.unique(y_val_sm))\n",
        "heat_cm3.index.name = 'Actual'\n",
        "heat_cm3.columns.name = 'Predicted'\n",
        "\n",
        "heat_cm4 = pd.DataFrame(confusion_matrix_cbt, columns=np.unique(y_val_sm), index = np.unique(y_val_sm))\n",
        "heat_cm4.index.name = 'Actual'\n",
        "heat_cm4.columns.name = 'Predicted'\n",
        "\n",
        "f, ax = plt.subplots(1, 5, figsize=(20,8))\n",
        "f.subplots_adjust(left=None, bottom=None, right= 2, top=None, wspace=None, hspace= None)\n",
        "\n",
        "sns.heatmap(heat_cm0, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[0])\n",
        "ax[0].set_title('Regresión logística', fontsize = 20)\n",
        "sns.heatmap(heat_cm1, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[1])\n",
        "ax[1].set_title('XGBoost', fontsize = 20)\n",
        "sns.heatmap(heat_cm2, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[2])\n",
        "ax[2].set_title('Random Forest', fontsize = 20)\n",
        "sns.heatmap(heat_cm3, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[3])\n",
        "ax[3].set_title('Gradient Boosting', fontsize = 20)\n",
        "sns.heatmap(heat_cm4, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[4])\n",
        "ax[4].set_title('Catboost', fontsize = 20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N1UYmL_fG_3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_gbc = best_est_gbc.predict(X_test)\n",
        "test_pred_cbt = best_est_cbt.predict(X_test)"
      ],
      "metadata": {
        "id": "cz2KSTsXHH9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_gbc = confusion_matrix(y_test, test_pred_gbc, normalize='true')\n",
        "confusion_matrix_cbt = confusion_matrix(y_test, test_pred_cbt, normalize='true')\n",
        "\n",
        "heat_cm0 = pd.DataFrame(confusion_matrix_gbc, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "heat_cm0.index.name = 'Actual'\n",
        "heat_cm0.columns.name = 'Predicted'\n",
        "\n",
        "heat_cm1 = pd.DataFrame(confusion_matrix_cbt, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "heat_cm1.index.name = 'Actual'\n",
        "heat_cm1.columns.name = 'Predicted'\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(15,8))\n",
        "f.subplots_adjust(left=None, bottom=None, right= 2, top=None, wspace=None, hspace= None)\n",
        "\n",
        "sns.heatmap(heat_cm0, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[0])\n",
        "ax[0].set_title('Gradient Boosting', fontsize = 20)\n",
        "sns.heatmap(heat_cm1, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g', ax = ax[1])\n",
        "ax[1].set_title('Catboost', fontsize = 20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fboPcLc6HJDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, test_pred_gbc, target_names=label))"
      ],
      "metadata": {
        "id": "aGeQurgAHOPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, test_pred_cbt, target_names=label))"
      ],
      "metadata": {
        "id": "YWlc_HXGHPXz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}